{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Load essential libraries**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UVQzMgj6F2w_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_hN0a9Rem7K"
      },
      "source": [
        "## Load modules\n",
        "\n",
        "# Standard modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# Preprocessing modules\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler,\\\n",
        " OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Train-test split module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dimension reduction module\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Classifier module\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Pipeline modules\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Performance metric modules\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Plotting modules\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (4.0, 4.0) # set default size of plots\n",
        "\n",
        "pd.options.display.max_columns = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPo9arBOE-JN"
      },
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n",
        "    # depending on how data is organized inside your Colab Notebooks folder in\n",
        "    # Google Drive\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/OddSem2024MAHE'\n",
        "    DATA_DIR = DIR+'/Data/'\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load ICU Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uPwwlJM9HC9Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dlxWVPXHHhs"
      },
      "source": [
        "## Load ICU Data\n",
        "file = DATA_DIR+'ICU_Complete.csv'\n",
        "dfICU = pd.read_csv(file)\n",
        "dfICU.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Drop the 'In-hospital_death' and 'Length_of_stay' columns as we will develop a prospective model which takes as input information available at the time of patient admission and will predict whether a patient will need mechanical ventilation or not.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Md_h3SNpIqnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop the 'In-hospital_death' and 'Length_of_stay' columns\n",
        "dfICU.drop(['In-hospital_death', 'Length_of_stay'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "H6Cf1weOIsqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Create lists of categorical and continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aMV5mf-DHHXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create lists of categorical and continuous features\n",
        "categorical_features = ['Gender', 'MechVent']\n",
        "continuous_features = dfICU.columns[~dfICU.columns.isin(categorical_features)].to_list()\n",
        "dfICU.dtypes"
      ],
      "metadata": {
        "id": "k_cxa8koHNbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Convert categorical features to the categorical type\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MF3WZk-oHT79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfICU[categorical_features] = dfICU[categorical_features].astype('category')\n",
        "dfICU.dtypes"
      ],
      "metadata": {
        "id": "6azvoBahHYB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "How balanced is the dataset w.r.t. the target variable 'MechVent'?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WdpipRBnI673"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How balanced is the dataset w.r.t. the target variable 'MechVent'?\n",
        "dfICU['MechVent'].value_counts().plot(kind = 'barh');"
      ],
      "metadata": {
        "id": "iKox08NtJDt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Remove the target variable 'MechVent' from the list of categorical features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VuUUu7zmPMqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove the target variable 'MechVent' from the list of categorical features\n",
        "categorical_features.remove('MechVent')"
      ],
      "metadata": {
        "id": "c6K4UxGqPIEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Stratified train and test split of the data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zH1ZXX4RKWL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Stratified train and test split of the data\n",
        "X = dfICU.drop('MechVent', axis = 1)\n",
        "y = dfICU['MechVent']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify = y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 1)\n",
        "print(f'{X_train.shape[0]} training samples and {X_test.shape[0]} test samples')"
      ],
      "metadata": {
        "id": "lZEApPAhKTis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(y_train == 'No'))\n",
        "print(np.mean(y_train == 'Yes'))\n",
        "\n",
        "print(np.mean(y_test == 'No'))\n",
        "print(np.mean(y_test == 'Yes'))"
      ],
      "metadata": {
        "id": "OVF_xGqw2rnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Build preprocessing pipeline for categorical and continuous features\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K7wnMgSIHa6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build pipeline for continuous and categorical features\n",
        "\n",
        "# Pipeline object for continuous features\n",
        "continuous_transformer = Pipeline(steps = [('scaler', StandardScaler()),\n",
        "                                           ('pca', PCA(n_components = 7))])\n",
        "\n",
        "# Pipeline object for categorical features\n",
        "categorical_transformer = Pipeline(steps = [('onehotenc', OneHotEncoder(handle_unknown = 'ignore'))])\n",
        "\n",
        "\n",
        "# Create a preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('continuous', continuous_transformer, continuous_features),\n",
        "                                                 ('categorical', categorical_transformer, categorical_features)\n",
        "                                                 ],\n",
        "                                 remainder = 'passthrough'\n",
        "                                 )\n",
        "\n",
        "# Define a classifier object\n",
        "classifier = GradientBoostingClassifier()\n",
        "\n",
        "# Define the entire classification model\n",
        "model = Pipeline(steps = [('preprocessor', preprocessor), ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "w9Ca7uPSi2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Fit the model on the train data and test on the test data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r2jc-zGVNXw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fit the model on the train data and test on the test data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the output labels for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "J1lMO7ucNWhv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}